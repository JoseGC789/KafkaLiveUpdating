# Event Status Service

This POC purpose is to manage the live status of sports events, periodically poll an external service for updated scores, and publish those scores to a Kafka topic. It exposes a REST API to toggle event polling on or off and ensures asynchronous, fault-tolerant integration with external systems using scheduling and Kafka messaging.

This code was created with speed in mind at the cost of quality since the challenge is to build it in around 90 minutes. This was done by heavily using code generation LLMs.

## Quick Guide
Install Docker and dockerfile then:

Run by:
```bash
    docker-compose up --build
```

Use the application with:
```bash
    curl --location 'http://localhost:8080/events/status' \
    --header 'Content-Type: application/json' \
    --data '{
        "eventId": "f3eb7d92-951a-41b6-a6fe-a3049a40f183",
        "status": true
    }'
```

Take down the app by:
```bash
    docker-compose down
```

If you don't want to run all in the same docker-compose then:

Run KAFKA by:
```bash
    docker-compose -f .\docker-compose-no-app.yml up
```

Compile the project:

```bash
    mvn clean package
```

Run the application with:

```bash
    java -jar .\target\event-status-service-0.0.1-SNAPSHOT.jar
```

Use the application with:
```bash
    curl --location 'http://localhost:8080/events/status' \
    --header 'Content-Type: application/json' \
    --data '{
        "eventId": "f3eb7d92-951a-41b6-a6fe-a3049a40f183",
        "status": true
    }'
```

Take down the app by:
```bash
    docker-compose down
```


## Overview

This is a Spring Boot microservice that tracks the live status of sports events and periodically fetches live scores for events marked as "live." The scores are then published to a Kafka topic for downstream consumers.

- **REST API**: Accepts event status updates (`live` or `not_live`).
- **Scheduling**: For each live event, schedules a job every 10 seconds to fetch the current score.
- **External Service**: Simulated external service mock returns randomized score data.
- **Kafka Integration**: Publishes score updates as JSON messages to a Kafka topic named `event-scores`.
- **In-memory Store**: Uses a thread-safe concurrent map to track scheduled tasks per event.
- **Logging**: Uses SLF4J with Logback for structured logging.
- **Validation**: Request input is validated using Jakarta Bean Validation (`@NotBlank`, etc.).

---

## Design Choices

- **In-Memory Scheduling**: Uses `ThreadPoolTaskScheduler` to manage periodic polling of external scores per live event.
- **ConcurrentHashMap**: Tracks scheduled futures keyed by event ID to allow cancellation when event goes offline.
- **KafkaTemplate + CompletableFuture**: Asynchronously publishes messages with logging on success/failure.
- **ExternalServiceMock**: Simulates external REST API for current score; designed as a Spring component for easy replacement.
- **Validation and Logging**: Input validation and detailed logging for operational transparency.
- **Separation of Concerns**: Controller handles HTTP requests, service contains core business logic, external service is abstracted for testability.

---

## AI Usage

Parts (the majority) of the code, tests, and Docker-related instructions have been assisted and generated using OpenAI's ChatGPT language model. All code has been reviewed and adapted for your specific requirements.
Prompting is included under llm-prompting directory

## Non AI Usage

Utilized this example https://dzone.com/articles/building-kafka-producer-with-spring-boot to verify and improve code generated by LLMs and with heavy use of BDD techniques with POSTMAN.

---

## Prerequisites

- Java 17+
- Maven 3.6+
- Docker & Docker Compose
- Kafka broker accessible via Docker Compose setup (included)

---

## Build Instructions

1. Clone the repository:
   ```bash
   git clone <repository-url>
   cd event-status-service

2. Build the project with Maven:
   ```bash
   mvn clean package

## Running the Application

### Kafka Setup

Start Kafka and Zookeeper using Docker Compose (ensure your `docker-compose.yml` includes Kafka services):

```bash
    docker-compose up -d
```

Make sure Kafka is running and accessible on the default ports.

### Run the Spring Boot Application

Run the packaged jar:

```bash
    java -jar target/event-status-service-0.0.1-SNAPSHOT.jar
```

The service will start on port 8080 by default.

## Usage Example

Send a POST request to update the event status (mark live or not live):

```bash
    curl --location 'http://localhost:8080/events/status' \
    --header 'Content-Type: application/json' \
    --data '{
        "eventId": "f3eb7d92-951a-41b6-a6fe-a3049a40f183",
        "status": true
    }'
```
* Setting "status": true starts polling for that eventâ€™s live score every 10 seconds and publishes updates to Kafka.
* Setting "status": false stops polling and removes scheduled tasks for the event.

## Testing

Run unit and integration tests with Maven:

```bash
  mvn test
```

Tests cover:

* REST API controller behavior

* Event scheduling and cancellation logic

* Kafka publishing with asynchronous callbacks

* External service mocking and error handling

### Notes
The external score fetching is simulated with ExternalServiceMock. Replace or extend with a real REST API client as needed.

Kafka topic event-scores is created automatically on startup via KafkaProducerConfig.

The scheduling uses a fixed thread pool with size 10; adjust as necessary for production workloads.

Logs include detailed success and error messages for traceability.

For production:
* consider externalizing configuration (Kafka brokers, topic names, scheduler pool size, etc.) via application.yml or environment variables.
* apply a better aproach for distributed system. This POC assumes single kubernetes pod.
